{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c13c9ce",
   "metadata": {},
   "source": [
    "# INFO 2950 Final Project Appendix\n",
    "Alex Joos (aaj46), Jasmine Pearson (jcp348), Darby Bayne (dpb99) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17240fa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef1a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import duckdb\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import re\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b863cee",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab2404",
   "metadata": {},
   "source": [
    "<a name=\"datacleaning\"></a>\n",
    "<a name=\"education\"></a>\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Education &#9664;</div>**\n",
    "\n",
    "This data came originally as a Numbers file. When saved as a CSV, we then had to split the columns by \";\". Other than that, the data was already cleaned and we had no other changes to make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67eb2528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>avg_years_of_schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1870</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1875</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1880</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1885</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1890</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Entity Code  Year  avg_years_of_schooling\n",
       "0  Afghanistan  AFG  1870                    0.01\n",
       "1  Afghanistan  AFG  1875                    0.01\n",
       "2  Afghanistan  AFG  1880                    0.01\n",
       "3  Afghanistan  AFG  1885                    0.01\n",
       "4  Afghanistan  AFG  1890                    0.01"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_df = pd.read_csv(\"schooling_years.csv\", delimiter=\";\")\n",
    "\n",
    "education_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6b323",
   "metadata": {},
   "source": [
    "We call head on the dataframe to visually confirm that the data was read in and deliminated correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1f826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df.to_csv(\"education_df\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ebcec",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a8393",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d29141",
   "metadata": {},
   "source": [
    "<a name=\"druguse\"></a>\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Drug Use &#9664;</div>**\n",
    "\n",
    "The data came in html format. Then, we read them using pd.read_html to access the files. This resulted in a list of dataframes. Since we only need to first data set, we sliced our input at the zeroth index and saved this to a new dataframe for each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5233335a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## loading in data for years 2017-2021\n",
    "## html inputs as list of dfs, we only want the first one\n",
    "drug_2021 = pd.read_html(\"drug_2021_stats.html\")\n",
    "stats_2021_df = drug_2021[0]\n",
    "\n",
    "drug_2020 = pd.read_html(\"drug_2020_2019_stats.html\")\n",
    "stats_2020_df = drug_2020[0]\n",
    "\n",
    "drug_2019 = pd.read_html(\"drug_2020_2019_stats.html\")\n",
    "stats_2019_df = drug_2019[0]\n",
    "\n",
    "drug_2018 = pd.read_html(\"drug_2018_2017_stats.html\")\n",
    "stats_2018_df = drug_2018[0]\n",
    "\n",
    "drug_2017 = pd.read_html(\"drug_2018_2017_stats.html\")\n",
    "stats_2017_df = drug_2017[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c23d7",
   "metadata": {},
   "source": [
    "We then combined these dataframes on Drug using a left join. \n",
    "\n",
    "Then, we filtered the new data set to only include the Past Year and Drug columns. After, we renamed the Year columns to be more readable, and manually inputted the required years. \n",
    "\n",
    "Next, we melted the dataframe to make it long instead of wide and got rid of the drug column, as it was unnecesary since all data was based on the same drug. \n",
    "\n",
    "Then, we reordered the Years to account for changes made by manual adding. We also convert years to strings and numbers as number values to prevent errors in future graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648df57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of Users (Thousands)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>4250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>4692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>5125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Number of Users (Thousands)\n",
       "0  2013                         4430\n",
       "1  2014                         4250\n",
       "2  2015                         4692\n",
       "3  2016                         4903\n",
       "4  2017                         5125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## getting data by joining on Drug column\n",
    "combined_df = stats_2018_df.join(stats_2019_df.set_index('Drug'), \n",
    "                                 on='Drug', how='left', lsuffix='2017', \n",
    "                                 rsuffix='2018')\n",
    "\n",
    "combined_df = combined_df.join(stats_2021_df.set_index('Drug'), \n",
    "                               on='Drug', how='left', rsuffix='2019')\n",
    "\n",
    "combined_df = combined_df.filter(regex='Past Year|Drug', axis=1)\n",
    "\n",
    "## getting data for only hallucinogenic drugs \n",
    "hal_df = combined_df[combined_df['Drug'] == \"Hallucinogens\"]\n",
    "hal_df = hal_df.rename(columns = {'Past Year (2017)': '2017', \n",
    "                                   'Past Year (2018)': '2018',\n",
    "                                   'Past Year (2019)': '2019',\n",
    "                                   'Past Year (2020)': '2020',\n",
    "                                   'Past Year (2021)': '2021'})\n",
    "\n",
    "## manually inputing years 2013-2016 \n",
    "hal_df['2016'] = 4903\n",
    "hal_df['2015'] = 4692\n",
    "hal_df['2014'] = 4250\n",
    "hal_df['2013'] = 4430\n",
    "\n",
    "## melting wide to long, renaming columns \n",
    "hal_df = pd.melt(hal_df, id_vars=['Drug'], var_name='Year', \n",
    "                 value_name='Number of Users (Thousands)')\n",
    "\n",
    "## getting rid of drug category because its unecessary  \n",
    "hal_df = hal_df[['Year', 'Number of Users (Thousands)']]\n",
    "\n",
    "## since years go from 2021-2017 then 2016-2013, we sort by \n",
    "## years ascending, then reset the index \n",
    "hal_df = hal_df.sort_values(by='Year', ascending=True)\n",
    "hal_df = hal_df.reset_index(drop=True)\n",
    "\n",
    "## convert years to strings and numbers as number values to prevent errors\n",
    "## when graphing \n",
    "hal_df['Year'] = hal_df['Year'].astype(str)\n",
    "hal_df['Number of Users (Thousands)'] = pd.to_numeric(\n",
    "                                    hal_df['Number of Users (Thousands)'], \n",
    "                                    errors='coerce')\n",
    "\n",
    "## display \n",
    "hal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead9470",
   "metadata": {},
   "source": [
    "We call head on the dataframe to visually confirm that the data was read in correctly and that all of our seperate dataframs and manually inputted information appear as desired. \n",
    "\n",
    "\n",
    "\n",
    "Later, we realized that we were unable to properly use this data as it was only for the United States and covered very limited years. So, it does not appear in our final analysis and so we do not bother making it into a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13d481",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2703262b",
   "metadata": {},
   "source": [
    "<a name=\"internet\"></a>\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Internet Access &#9664;</div>**\n",
    "\n",
    "This data was originally a csv file. First we read it in and display the first five rows to bettern understand all of the columns we will be working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010cb891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>Unnamed: 67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Individuals using the Internet (% of population)</td>\n",
       "      <td>IT.NET.USER.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83.780000</td>\n",
       "      <td>88.661227</td>\n",
       "      <td>93.542454</td>\n",
       "      <td>97.170000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>AFE</td>\n",
       "      <td>Individuals using the Internet (% of population)</td>\n",
       "      <td>IT.NET.USER.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.237716</td>\n",
       "      <td>14.485849</td>\n",
       "      <td>15.753330</td>\n",
       "      <td>17.310987</td>\n",
       "      <td>20.063024</td>\n",
       "      <td>22.589591</td>\n",
       "      <td>24.988401</td>\n",
       "      <td>27.660654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Individuals using the Internet (% of population)</td>\n",
       "      <td>IT.NET.USER.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>AFW</td>\n",
       "      <td>Individuals using the Internet (% of population)</td>\n",
       "      <td>IT.NET.USER.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.923441</td>\n",
       "      <td>18.109485</td>\n",
       "      <td>22.869750</td>\n",
       "      <td>27.081219</td>\n",
       "      <td>32.089337</td>\n",
       "      <td>35.276448</td>\n",
       "      <td>41.749819</td>\n",
       "      <td>46.990497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Individuals using the Internet (% of population)</td>\n",
       "      <td>IT.NET.USER.ZS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>32.129392</td>\n",
       "      <td>32.550147</td>\n",
       "      <td>32.602302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Country Name Country Code  \\\n",
       "0                        Aruba          ABW   \n",
       "1  Africa Eastern and Southern          AFE   \n",
       "2                  Afghanistan          AFG   \n",
       "3   Africa Western and Central          AFW   \n",
       "4                       Angola          AGO   \n",
       "\n",
       "                                     Indicator Name  Indicator Code  1960  \\\n",
       "0  Individuals using the Internet (% of population)  IT.NET.USER.ZS   NaN   \n",
       "1  Individuals using the Internet (% of population)  IT.NET.USER.ZS   NaN   \n",
       "2  Individuals using the Internet (% of population)  IT.NET.USER.ZS   NaN   \n",
       "3  Individuals using the Internet (% of population)  IT.NET.USER.ZS   NaN   \n",
       "4  Individuals using the Internet (% of population)  IT.NET.USER.ZS   NaN   \n",
       "\n",
       "   1961  1962  1963  1964  1965  ...       2014       2015       2016  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  ...  83.780000  88.661227  93.542454   \n",
       "1   NaN   NaN   NaN   NaN   NaN  ...  12.237716  14.485849  15.753330   \n",
       "2   NaN   NaN   NaN   NaN   NaN  ...   7.000000   8.260000  11.000000   \n",
       "3   NaN   NaN   NaN   NaN   NaN  ...  14.923441  18.109485  22.869750   \n",
       "4   NaN   NaN   NaN   NaN   NaN  ...  21.400000  22.000000  23.200000   \n",
       "\n",
       "        2017       2018       2019       2020       2021  2022  Unnamed: 67  \n",
       "0  97.170000        NaN        NaN        NaN        NaN   NaN          NaN  \n",
       "1  17.310987  20.063024  22.589591  24.988401  27.660654   NaN          NaN  \n",
       "2  13.500000  16.800000  17.600000  18.400000        NaN   NaN          NaN  \n",
       "3  27.081219  32.089337  35.276448  41.749819  46.990497   NaN          NaN  \n",
       "4  26.000000  29.000000  32.129392  32.550147  32.602302   NaN          NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internet_df = pd.read_csv('internet_access_by_country 1989-2022.csv', \n",
    "                          thousands=\",\")\n",
    "internet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32014e",
   "metadata": {},
   "source": [
    "The final Column, indicator name, and indicator code were uneeded for our research. We kept both of the country columns since we will likely use country code, but the names will be helpful for reference. \n",
    "\n",
    "Because we are joining the data on year and country, we wanted a year column, and to get that needed a vertical data frame.\n",
    "\n",
    "We used pd.melt to put all of the years into the the \"year\" column, and their corresponding internet access percentage into the \"internet access\" column. We chose to keep NaN's because when joining the data frames together into a master it would be helpful to see which country-time mixes have full breadth of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fba0c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>year</th>\n",
       "      <th>internet access</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>AFE</td>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>AFW</td>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Country Name Country Code  year  internet access\n",
       "0                        Aruba          ABW  1960              NaN\n",
       "1  Africa Eastern and Southern          AFE  1960              NaN\n",
       "2                  Afghanistan          AFG  1960              NaN\n",
       "3   Africa Western and Central          AFW  1960              NaN\n",
       "4                       Angola          AGO  1960              NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "internet_df = internet_df.drop(['Unnamed: 67', 'Indicator Name', 'Indicator Code'], \n",
    "                               axis=1)\n",
    "\n",
    "years_int = []\n",
    "for year in range(1960, 2023):\n",
    "    years_int.append(year)\n",
    "years_str = [str(year) for year in years_int]\n",
    "\n",
    "internet_df_melt = pd.melt(internet_df, \n",
    "                           id_vars=['Country Name','Country Code'], \n",
    "                           value_vars=years_str, \n",
    "                           var_name = 'year', \n",
    "                           value_name = 'internet access')\n",
    "internet_df.rename(columns = {'year': 'Year'})\n",
    "internet_df_melt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9b2b5",
   "metadata": {},
   "source": [
    "As done before, we continue to call head on the dataframe to visually make sure changes occurred as planned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d985ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_df.to_csv(\"internet_df\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6257675",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce28fed",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f551c",
   "metadata": {},
   "source": [
    "<a name=\"religion\"></a>\n",
    "\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Religion &#9664;</div>**\n",
    "\n",
    "First we read in the csv file. The data set originally had only rounded years up to 2010, so the sightings data will need a new column that shows the rounded year so religion can be matched to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2fae6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>code</th>\n",
       "      <th>christianity_protestant</th>\n",
       "      <th>christianity_romancatholic</th>\n",
       "      <th>christianity_easternorthodox</th>\n",
       "      <th>christianity_anglican</th>\n",
       "      <th>christianity_other</th>\n",
       "      <th>christianity_all</th>\n",
       "      <th>judaism_orthodox</th>\n",
       "      <th>...</th>\n",
       "      <th>jainism_percent</th>\n",
       "      <th>confucianism_percent</th>\n",
       "      <th>syncretism_percent</th>\n",
       "      <th>animism_percent</th>\n",
       "      <th>noreligion_percent</th>\n",
       "      <th>otherreligion_percent</th>\n",
       "      <th>religion_sumpercent</th>\n",
       "      <th>total_percent</th>\n",
       "      <th>dual_religion</th>\n",
       "      <th>source_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>66069671</td>\n",
       "      <td>38716742</td>\n",
       "      <td>1121898</td>\n",
       "      <td>2400000</td>\n",
       "      <td>1956807</td>\n",
       "      <td>110265118</td>\n",
       "      <td>821489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>73090083</td>\n",
       "      <td>42635882</td>\n",
       "      <td>3045420</td>\n",
       "      <td>3045420</td>\n",
       "      <td>1177214</td>\n",
       "      <td>122994019</td>\n",
       "      <td>1078078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>79294628</td>\n",
       "      <td>46402368</td>\n",
       "      <td>3454916</td>\n",
       "      <td>2572767</td>\n",
       "      <td>2277091</td>\n",
       "      <td>134001770</td>\n",
       "      <td>944000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>90692928</td>\n",
       "      <td>50587880</td>\n",
       "      <td>3334535</td>\n",
       "      <td>2710065</td>\n",
       "      <td>2908939</td>\n",
       "      <td>150234347</td>\n",
       "      <td>973500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>94165803</td>\n",
       "      <td>64761783</td>\n",
       "      <td>4792868</td>\n",
       "      <td>2822149</td>\n",
       "      <td>973155</td>\n",
       "      <td>167515758</td>\n",
       "      <td>991200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>1.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                     state code  christianity_protestant  \\\n",
       "0  1945  United States of America  USA                 66069671   \n",
       "1  1950  United States of America  USA                 73090083   \n",
       "2  1955  United States of America  USA                 79294628   \n",
       "3  1960  United States of America  USA                 90692928   \n",
       "4  1965  United States of America  USA                 94165803   \n",
       "\n",
       "   christianity_romancatholic  christianity_easternorthodox  \\\n",
       "0                    38716742                       1121898   \n",
       "1                    42635882                       3045420   \n",
       "2                    46402368                       3454916   \n",
       "3                    50587880                       3334535   \n",
       "4                    64761783                       4792868   \n",
       "\n",
       "   christianity_anglican  christianity_other  christianity_all  \\\n",
       "0                2400000             1956807         110265118   \n",
       "1                3045420             1177214         122994019   \n",
       "2                2572767             2277091         134001770   \n",
       "3                2710065             2908939         150234347   \n",
       "4                2822149              973155         167515758   \n",
       "\n",
       "   judaism_orthodox  ...  jainism_percent  confucianism_percent  \\\n",
       "0            821489  ...              0.0                   0.0   \n",
       "1           1078078  ...              0.0                   0.0   \n",
       "2            944000  ...              0.0                   0.0   \n",
       "3            973500  ...              0.0                   0.0   \n",
       "4            991200  ...              0.0                   0.0   \n",
       "\n",
       "   syncretism_percent  animism_percent  noreligion_percent  \\\n",
       "0                 0.0              0.0              0.1635   \n",
       "1                 0.0              0.0              0.1482   \n",
       "2                 0.0              0.0              0.1404   \n",
       "3                 0.0              0.0              0.1193   \n",
       "4                 0.0              0.0              0.1020   \n",
       "\n",
       "   otherreligion_percent  religion_sumpercent  total_percent  dual_religion  \\\n",
       "0                 0.0039               0.9961         1.0000              0   \n",
       "1                 0.0041               0.9959         1.0000              0   \n",
       "2                 0.0193               0.9807         0.9999              0   \n",
       "3                 0.0076               0.9924         0.9999              0   \n",
       "4                 0.0030               0.9970         1.0001              0   \n",
       "\n",
       "   source_code  \n",
       "0           13  \n",
       "1           18  \n",
       "2           15  \n",
       "3           13  \n",
       "4           20  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religions_df = pd.read_csv('religions_by_country_1945-2010.csv', thousands=\",\")\n",
    "religions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405bbc9",
   "metadata": {},
   "source": [
    "Then for each year-country pair, we looked through all of the non \"all\" religions. We chose not to do the all religions because they combine data from multiple others. Of all of the individual religions, the greatest population count per country was found and put into a new column called top_religion. We then changed the year column to rounded year so when this data joins to the other data frames it can map other years to the closest multiple of 5 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c60e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rounded year</th>\n",
       "      <th>code</th>\n",
       "      <th>topReligion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>USA</td>\n",
       "      <td>christianity_protestant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>USA</td>\n",
       "      <td>christianity_protestant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955</td>\n",
       "      <td>USA</td>\n",
       "      <td>christianity_protestant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>USA</td>\n",
       "      <td>christianity_protestant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>USA</td>\n",
       "      <td>christianity_protestant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rounded year code              topReligion\n",
       "0          1945  USA  christianity_protestant\n",
       "1          1950  USA  christianity_protestant\n",
       "2          1955  USA  christianity_protestant\n",
       "3          1960  USA  christianity_protestant\n",
       "4          1965  USA  christianity_protestant"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religions = []\n",
    "\n",
    "for i in range(len(religions_df.columns)):\n",
    "    column_name = religions_df.columns[i]\n",
    "    \n",
    "    if column_name in ['year', 'state', 'code']:\n",
    "        continue\n",
    "    if (religions_df[column_name].dtype == float):\n",
    "        religions_df[column_name]=pd.to_numeric(religions_df[column_name], \n",
    "                                downcast='integer')\n",
    "    religions.append(religions_df[column_name])\n",
    "    \n",
    "    if column_name == 'religion_all':\n",
    "        break\n",
    "        \n",
    "i = 0\n",
    "eachrow = 0\n",
    "topreligion = []\n",
    "max_index = 0\n",
    "\n",
    "#goes through all of the rows\n",
    "for eachrow in range(religions_df.shape[0]): \n",
    "    valuelist = []\n",
    "    \n",
    "    #checks each religion\n",
    "    for i in range(len(religions)): \n",
    "        #indexes the value of the religion in question\n",
    "        value = religions_df.iloc[eachrow, 3+i] \n",
    "        valuelist.append(value)\n",
    "        if (\"all\" in religions_df.columns[3+i]):\n",
    "            valuelist[-1] = 0\n",
    "    max_index = valuelist.index(max(valuelist))\n",
    "    topreligion.append(religions_df.columns[3+ max_index])\n",
    "    \n",
    "top_df = religions_df[['year', 'code']].copy()\n",
    "top_df['topReligion'] = topreligion\n",
    "religion_df = top_df.rename(columns={'year': 'rounded year'})\n",
    "religion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebd13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_df.to_csv(\"religion_df\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a001259",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5656db3",
   "metadata": {},
   "source": [
    "We call head on the dataframe to confirm all our changes have been made as desired.\n",
    "\n",
    "Then, we printed the code column and all unique religions just to see what we were working with, and because we later planned to join on the code column of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a739cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['christianity_protestant' 'christianity_romancatholic'\n",
      " 'christianity_anglican' 'islam_other' 'islam_sunni'\n",
      " 'christianity_easternorthodox' 'islam_shi’a' 'christianity_other'\n",
      " 'judaism_orthodox' 'islam_ibadhi' 'buddhism_other' 'buddhism_mahayana'\n",
      " 'buddhism_theravada']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['USA', 'CAN', 'BHM', 'CUB', 'HAI', 'DOM', 'JAM', 'TRI', 'BAR',\n",
       "       'DMA', 'GRN', 'SLU', 'SVG', 'AAB', 'SKN', 'MEX', 'BLZ', 'GUA',\n",
       "       'HON', 'SAL', 'NIC', 'COS', 'PAN', 'COL', 'VEN', 'GUY', 'SUR',\n",
       "       'ECU', 'PER', 'BRA', 'BOL', 'PAR', 'CHL', 'ARG', 'URU', 'UKG',\n",
       "       'IRE', 'NTH', 'BEL', 'LUX', 'FRN', 'MNC', 'LIE', 'SWZ', 'SPN',\n",
       "       'AND', 'POR', 'GMY', 'GFR', 'GDR', 'POL', 'AUS', 'HUN', 'CZE',\n",
       "       'CZR', 'SLO', 'ITA', 'SNM', 'MLT', 'ALB', 'MNG', 'MAC', 'CRO',\n",
       "       'YUG', 'BOS', 'KOS', 'SLV', 'GRC', 'CYP', 'BUL', 'MLD', 'ROM',\n",
       "       'RUS', 'EST', 'LAT', 'LIT', 'UKR', 'BLR', 'ARM', 'GRG', 'AZE',\n",
       "       'FIN', 'SWD', 'NOR', 'DEN', 'ICE', 'CAP', 'STP', 'GNB', 'EQG',\n",
       "       'GAM', 'MLI', 'SEN', 'BEN', 'MAA', 'NIR', 'CDI', 'GUI', 'BFO',\n",
       "       'LBR', 'SIE', 'GHA', 'TOG', 'CAO', 'NIG', 'GAB', 'CEN', 'CHA',\n",
       "       'CON', 'DRC', 'UGA', 'KEN', 'TAZ', 'BUI', 'RWA', 'SOM', 'DJI',\n",
       "       'ETH', 'ERI', 'ANG', 'MZM', 'ZAM', 'ZIM', 'MAW', 'SAF', 'NAM',\n",
       "       'LES', 'BOT', 'SWA', 'MAG', 'COM', 'MAS', 'SEY', 'MOR', 'ALG',\n",
       "       'TUN', 'LIB', 'SUD', 'IRN', 'TUR', 'IRQ', 'EGY', 'SYR', 'LEB',\n",
       "       'JOR', 'ISR', 'SAU', 'YAR', 'YEM', 'YPR', 'KUW', 'BAH', 'QAT',\n",
       "       'UAE', 'OMA', 'AFG', 'TKM', 'TAJ', 'KYR', 'UZB', 'KZK', 'CHN',\n",
       "       'MON', 'TAW', 'PRK', 'ROK', 'JPN', 'IND', 'BHU', 'PAK', 'BNG',\n",
       "       'MYA', 'SRI', 'MAD', 'NEP', 'THI', 'CAM', 'LAO', 'DRV', 'RVN',\n",
       "       'MAL', 'SIN', 'BRU', 'PHI', 'INS', 'ETM', 'AUL', 'PNG', 'NEW',\n",
       "       'VAN', 'SOL', 'KIR', 'TUV', 'FIJ', 'TON', 'NAU', 'MSI', 'PAL',\n",
       "       'FSM', 'WSM'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(religion_df['topReligion'].unique())\n",
    "religion_df['code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e46c5",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341b80c",
   "metadata": {},
   "source": [
    "<a name=\"political\"></a>\n",
    "\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Political Spectrum &#9664;</div>**\n",
    "\n",
    "The original data set contained data of each selected country's democracy index, measuring Full democracies as 10-8.01, Flawed democracies as 8-6.01, Hybrid regimes from 6-4.01, Authoritarian regimes from 4-0, and No data as excluded countries. \n",
    "\n",
    "The code essentially runs through the steps from Discussion 3, by making sure its the right requests.get, then turns the file into text, then into html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7b339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>2022 rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Regime type</th>\n",
       "      <th>2022</th>\n",
       "      <th>2021</th>\n",
       "      <th>2020</th>\n",
       "      <th>2019</th>\n",
       "      <th>2018</th>\n",
       "      <th>2017</th>\n",
       "      <th>2016</th>\n",
       "      <th>2015</th>\n",
       "      <th>2014</th>\n",
       "      <th>2013</th>\n",
       "      <th>2012</th>\n",
       "      <th>2011</th>\n",
       "      <th>2010</th>\n",
       "      <th>2008</th>\n",
       "      <th>2006</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North America</td>\n",
       "      <td>12</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Full democracy</td>\n",
       "      <td>8.88</td>\n",
       "      <td>8.87</td>\n",
       "      <td>9.24</td>\n",
       "      <td>9.22</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.07</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North America</td>\n",
       "      <td>30</td>\n",
       "      <td>United States</td>\n",
       "      <td>Flawed democracy</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.96</td>\n",
       "      <td>7.96</td>\n",
       "      <td>7.98</td>\n",
       "      <td>7.98</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.11</td>\n",
       "      <td>8.18</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Western Europe</td>\n",
       "      <td>20</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Full democracy</td>\n",
       "      <td>8.20</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.29</td>\n",
       "      <td>8.29</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.41</td>\n",
       "      <td>8.54</td>\n",
       "      <td>8.54</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.62</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Western Europe</td>\n",
       "      <td>36</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Flawed democracy</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Western Europe</td>\n",
       "      <td>37</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>Flawed democracy</td>\n",
       "      <td>7.38</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.59</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.53</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Region  2022 rank        Country       Regime type  2022  2021  \\\n",
       "0   North America         12         Canada    Full democracy  8.88  8.87   \n",
       "1   North America         30  United States  Flawed democracy  7.85  7.85   \n",
       "2  Western Europe         20        Austria    Full democracy  8.20  8.07   \n",
       "3  Western Europe         36        Belgium  Flawed democracy  7.64  7.51   \n",
       "4  Western Europe         37         Cyprus  Flawed democracy  7.38  7.43   \n",
       "\n",
       "   2020  2019  2018  2017  2016  2015  2014  2013  2012  2011  2010  2008  \\\n",
       "0  9.24  9.22  9.15  9.15  9.15  9.08  9.08  9.08  9.08  9.08  9.08  9.07   \n",
       "1  7.92  7.96  7.96  7.98  7.98  8.05  8.11  8.11  8.11  8.11  8.18  8.22   \n",
       "2  8.16  8.29  8.29  8.42  8.41  8.54  8.54  8.48  8.62  8.49  8.49  8.49   \n",
       "3  7.51  7.64  7.78  7.78  7.77  7.93  7.93  8.05  8.05  8.05  8.05  8.16   \n",
       "4  7.56  7.59  7.59  7.59  7.65  7.53  7.40  7.29  7.29  7.29  7.29  7.70   \n",
       "\n",
       "   2006  \n",
       "0  9.07  \n",
       "1  8.22  \n",
       "2  8.69  \n",
       "3  8.15  \n",
       "4  7.60  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_democracy_url = \"https://en.m.wikipedia.org/wiki/The_Economist_Democracy_Index\"\n",
    "\n",
    "\n",
    "wiki_democracy_result = requests.get(wiki_democracy_url)\n",
    "\n",
    "\n",
    "if wiki_democracy_result.status_code != 200:\n",
    "    print(\"something went wrong:\", wiki_democracy_result)\n",
    "    \n",
    "wiki_democracy_text = wiki_democracy_result.text\n",
    "\n",
    "wiki_democracy_html = BeautifulSoup(wiki_democracy_text, \"html.parser\")\n",
    "\n",
    "\n",
    "country_democracy_list = wiki_democracy_html.find_all('table',\n",
    "attrs={'class':\"wikitable sortable\",\n",
    "        'style':\"text-align:center;\"})\n",
    "\n",
    "\n",
    "country_democracy_df = pd.read_html(str(country_democracy_list))[1]\n",
    "\n",
    "country_democracy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cbc4a6",
   "metadata": {},
   "source": [
    "Now that we have confirmed that we have correctly scraped the data from wikipedia, we renamed columns to snake case to make them more readable and easier to refer to later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b9bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_democracy_df = country_democracy_df.rename(\n",
    "        columns = {\"Regime type\":\"Regime_Type\",\n",
    "        \"2022 rank\":\"2022_Rank\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bf206",
   "metadata": {},
   "source": [
    "Then, we took all of the year columns and turned them into one large year column in order to more easily merge the data together. This way, we can keep the democracy index values while also puting it aside the other values in the same year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc7b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_democracy_df = country_democracy_df.melt(\n",
    "    id_vars = [\"Region\",\"2022_Rank\",\"Country\",\"Regime_Type\"],\n",
    "    value_vars = [\"2022\",\"2021\",\"2020\",\"2019\",\"2018\",\"2017\",\n",
    "                  \"2016\",\"2015\",\"2014\",\"2013\",\"2012\",\"2011\",\"2010\"], \n",
    "    var_name = \"Year\", \n",
    "    value_name = \"Democracy_Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ca256",
   "metadata": {},
   "source": [
    "Finally, we drop columns that we don't need for our analysis: Region and 2022_Rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20291d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Regime_Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Democracy_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Full democracy</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Flawed democracy</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Full democracy</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>Flawed democracy</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>Flawed democracy</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country       Regime_Type  Year  Democracy_Index\n",
       "0         Canada    Full democracy  2022             8.88\n",
       "1  United States  Flawed democracy  2022             7.85\n",
       "2        Austria    Full democracy  2022             8.20\n",
       "3        Belgium  Flawed democracy  2022             7.64\n",
       "4         Cyprus  Flawed democracy  2022             7.38"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_df = country_democracy_df.drop(\n",
    "                ['Region', '2022_Rank'], \n",
    "                  axis=1)\n",
    "\n",
    "political_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408210b",
   "metadata": {},
   "source": [
    "We call head on the dataframe to confirm all our changes have been made as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e5645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_df.to_csv(\"scrubbed_democracy_df\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86229336",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7124c",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd4223",
   "metadata": {},
   "source": [
    "<a name=\"wealth\"></a>\n",
    "\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Wealth &#9664;</div>**\n",
    "\n",
    "We follow the same loading process from a Wikipedia page as from our prior analysis of Political Spectrum. First, we handle data from years 2000 to 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477ceb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>India</th>\n",
       "      <th>Italy</th>\n",
       "      <th>Japan</th>\n",
       "      <th>South Korea</th>\n",
       "      <th>Spain</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Aggregate share of the top 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>—</td>\n",
       "      <td>2.2%</td>\n",
       "      <td>3.1%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>—</td>\n",
       "      <td>4.7%</td>\n",
       "      <td>16.5%</td>\n",
       "      <td>1.5%</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>36.9%</td>\n",
       "      <td>81.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>—</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>3.6%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>—</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>1.5%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>38.8%</td>\n",
       "      <td>81.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>—</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>5.5%</td>\n",
       "      <td>—</td>\n",
       "      <td>5.3%</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>1.7%</td>\n",
       "      <td>2.9%</td>\n",
       "      <td>6.1%</td>\n",
       "      <td>35.1%</td>\n",
       "      <td>80.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>1.9%</td>\n",
       "      <td>2.2%</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>5.8%</td>\n",
       "      <td>—</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>—</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>6.2%</td>\n",
       "      <td>32.8%</td>\n",
       "      <td>79.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>1.9%</td>\n",
       "      <td>2.2%</td>\n",
       "      <td>3.9%</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>—</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>11.5%</td>\n",
       "      <td>—</td>\n",
       "      <td>3.9%</td>\n",
       "      <td>6.5%</td>\n",
       "      <td>32.5%</td>\n",
       "      <td>79.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Australia Canada China France Germany India Italy  Japan South Korea  \\\n",
       "0  2000         —   2.2%  3.1%   4.0%    5.2%     —  4.7%  16.5%        1.5%   \n",
       "1  2001         —   2.1%  3.6%   4.0%    5.2%     —  4.6%  14.1%        1.5%   \n",
       "2  2002         —   2.0%  3.7%   4.6%    5.5%     —  5.3%  13.8%        1.7%   \n",
       "3  2003      1.9%   2.2%  3.7%   5.2%    5.8%     —  5.7%  12.9%           —   \n",
       "4  2004      1.9%   2.2%  3.9%   5.6%    5.7%     —  5.7%  11.5%           —   \n",
       "\n",
       "  Spain United Kingdom United States Aggregate share of the top 10  \n",
       "0  2.1%           5.6%         36.9%                         81.8%  \n",
       "1  2.3%           5.6%         38.8%                         81.8%  \n",
       "2  2.9%           6.1%         35.1%                         80.7%  \n",
       "3  3.5%           6.2%         32.8%                         79.9%  \n",
       "4  3.9%           6.5%         32.5%                         79.4%  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_wealth_url = \"https://en.wikipedia.org/wiki/List_of_countries_by_total_wealth\"\n",
    "\n",
    "wiki_wealth_result = requests.get(wiki_wealth_url)\n",
    "\n",
    "if wiki_wealth_result.status_code != 200:\n",
    "    print(\"something went wrong:\", wiki_wealth_result)\n",
    "    \n",
    "wiki_wealth_text = wiki_wealth_result.text\n",
    "\n",
    "wiki_wealth_html = BeautifulSoup(wiki_wealth_text, \"html.parser\")\n",
    "\n",
    "country_wealth_list = wiki_wealth_html.find_all('table',\n",
    "attrs={'class':\"wikitable sortable\"})\n",
    "\n",
    "country_wealth_df_0to9 = pd.read_html(str(country_wealth_list))[0]\n",
    "\n",
    "country_wealth_df_0to9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8209c10",
   "metadata": {},
   "source": [
    "This next one is for years 2010-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "275d81e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>India</th>\n",
       "      <th>Italy</th>\n",
       "      <th>Japan</th>\n",
       "      <th>South Korea</th>\n",
       "      <th>Spain</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Aggregate share of the top 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>—</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>10.1%</td>\n",
       "      <td>5.4%</td>\n",
       "      <td>4.7%</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>11.4%</td>\n",
       "      <td>—</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>25.7%</td>\n",
       "      <td>75.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>—</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>11.9%</td>\n",
       "      <td>5.1%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>2.5%</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>11.4%</td>\n",
       "      <td>—</td>\n",
       "      <td>3.4%</td>\n",
       "      <td>4.5%</td>\n",
       "      <td>25.2%</td>\n",
       "      <td>75.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>—</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>4.2%</td>\n",
       "      <td>9.8%</td>\n",
       "      <td>—</td>\n",
       "      <td>2.9%</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>25.6%</td>\n",
       "      <td>74.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>—</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>4.8%</td>\n",
       "      <td>4.7%</td>\n",
       "      <td>2.6%</td>\n",
       "      <td>4.1%</td>\n",
       "      <td>7.8%</td>\n",
       "      <td>—</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>4.5%</td>\n",
       "      <td>26.8%</td>\n",
       "      <td>74.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>2.2%</td>\n",
       "      <td>2.6%</td>\n",
       "      <td>15.1%</td>\n",
       "      <td>4.2%</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>3.9%</td>\n",
       "      <td>7.1%</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>4.7%</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>75.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Australia Canada  China France Germany India Italy  Japan South Korea  \\\n",
       "0  2010         —   2.7%  10.1%   5.4%    4.7%  2.7%  4.6%  11.4%           —   \n",
       "1  2011         —   2.7%  11.9%   5.1%    4.6%  2.5%  4.3%  11.4%           —   \n",
       "2  2012         —   2.8%  12.5%   4.8%    4.6%  2.7%  4.2%   9.8%           —   \n",
       "3  2013         —   2.7%  13.8%   4.8%    4.7%  2.6%  4.1%   7.8%           —   \n",
       "4  2014      2.2%   2.6%  15.1%   4.2%    4.3%  2.8%  3.9%   7.1%           —   \n",
       "\n",
       "  Spain United Kingdom United States Aggregate share of the top 10  \n",
       "0  3.5%           4.4%         25.7%                         75.2%  \n",
       "1  3.4%           4.5%         25.2%                         75.6%  \n",
       "2  2.9%           4.4%         25.6%                         74.3%  \n",
       "3  2.7%           4.5%         26.8%                         74.5%  \n",
       "4     —           4.7%         28.6%                         75.5%  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_wealth_df_10to19 = pd.read_html(str(country_wealth_list))[1]\n",
    "\n",
    "country_wealth_df_10to19.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4dfc87",
   "metadata": {},
   "source": [
    "Lastly, we handle years 2020-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b565cc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Canada</th>\n",
       "      <th>China</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>India</th>\n",
       "      <th>Italy</th>\n",
       "      <th>Japan</th>\n",
       "      <th>South Korea</th>\n",
       "      <th>Spain</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>United States</th>\n",
       "      <th>Aggregate share of the top 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>—</td>\n",
       "      <td>2.5%</td>\n",
       "      <td>17.5%</td>\n",
       "      <td>3.9%</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>2.9%</td>\n",
       "      <td>6.3%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>—</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>29.9%</td>\n",
       "      <td>76.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>18.5%</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>3.2%</td>\n",
       "      <td>2.5%</td>\n",
       "      <td>5.4%</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>3.6%</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>77.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>—</td>\n",
       "      <td>2.5%</td>\n",
       "      <td>18.6%</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>3.8%</td>\n",
       "      <td>3.4%</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>5.0%</td>\n",
       "      <td>2.2%</td>\n",
       "      <td>—</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>30.8%</td>\n",
       "      <td>75.7%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Australia Canada  China France Germany India Italy Japan South Korea  \\\n",
       "0  2020         —   2.5%  17.5%   3.9%    4.3%  3.0%  2.9%  6.3%        2.3%   \n",
       "1  2021      2.3%   2.7%  18.5%   3.5%    4.0%  3.2%  2.5%  5.4%           —   \n",
       "2  2022         —   2.5%  18.6%   3.5%    3.8%  3.4%  2.4%  5.0%        2.2%   \n",
       "\n",
       "  Spain United Kingdom United States Aggregate share of the top 10  \n",
       "0     —           3.7%         29.9%                         76.3%  \n",
       "1     —           3.6%         31.3%                         77.0%  \n",
       "2     —           3.5%         30.8%                         75.7%  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_wealth_df_20to22 = pd.read_html(str(country_wealth_list))[2]\n",
    "\n",
    "country_wealth_df_20to22.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cb2bc",
   "metadata": {},
   "source": [
    "Now we use the concat function to append all three to into one big data set covering years 2000 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8b420a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined1 = pd.concat([country_wealth_df_0to9, country_wealth_df_10to19], \n",
    "                      ignore_index=True)\n",
    "combined = pd.concat([combined1,country_wealth_df_20to22],\n",
    "                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c1c51",
   "metadata": {},
   "source": [
    "Lastly, we make a country column using the melt function in order to compare the values easier in later steps. We also strip away the % symbol and rename the column as percent to follow as we turn the values into floats.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b31b1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Wealth_share_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Countries  Wealth_share_percent\n",
       "0  2000  Australia                   NaN\n",
       "1  2001  Australia                   NaN\n",
       "2  2002  Australia                   NaN\n",
       "3  2003  Australia                   1.9\n",
       "4  2004  Australia                   1.9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wealth_df = combined.melt(id_vars = [\"Year\"],\n",
    "value_vars = [\"Australia\",\"Canada\",\"China\",\"France\",\"Germany\",\"India\",\"Italy\",\n",
    "            \"Japan\",\"South Korea\",\"Spain\",\"United Kingdom\",\"United States\"],\n",
    "var_name = \"Countries\", value_name = \"Wealth_share_percent\")\n",
    "\n",
    "wealth_df[\"Wealth_share_percent\"]=wealth_df[\"Wealth_share_percent\"].str.rstrip(\"%\")\n",
    "wealth_df = wealth_df.replace(\"—\", np.nan, regex=True)\n",
    "wealth_df[\"Wealth_share_percent\"] = wealth_df[\"Wealth_share_percent\"].astype(float)\n",
    "wealth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e87e46",
   "metadata": {},
   "source": [
    "We call head on the dataframe to confirm all our changes have been made as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb1d20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wealth_df.to_csv(\"wealth_info\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4a59c",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b46e3",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444fb884",
   "metadata": {},
   "source": [
    "<a name=\"ufoone\"></a>\n",
    "\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: UFO Sightings, Part One &#9664;</div>**\n",
    "This data was originally a csv file, and we kept it that way. From Kaggle, we chose to take the data that was already scrubbed, which accounted for missing cells with NaN values. We set low_memory=False as the duration column has different time formating (we do this for visual purposes to prevent an error message, since we do not use this column we do not need to fix the data to be in one unit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3097ebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime                  city state country     shape  \\\n",
       "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
       "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
       "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
       "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
       "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load in scrubbed data \n",
    "scrubbed_location_df = pd.read_csv(\"scrubbed.csv\", \n",
    "                                   low_memory=False) \n",
    "## make copy of df for later use \n",
    "time_df = scrubbed_location_df\n",
    "\n",
    "scrubbed_location_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95312922",
   "metadata": {},
   "source": [
    "Then, we just pulled the columns pertinent to our analysis, datetime and country, from this data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8100daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting just time and country data\n",
    "scrubbed_location_df = duckdb.sql(\"SELECT datetime, country FROM\\\n",
    "                                scrubbed_location_df\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007b75e",
   "metadata": {},
   "source": [
    "Now we add a new column with just the year in order to make it easier to graph the data and to merge it with other dataframes. This adjust_time function is from the original Kaggle link on this data set. The use of the function is original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2439e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>us</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>gb</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>us</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>us</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime country  year\n",
       "0  10/10/1949 20:30      us  1949\n",
       "1  10/10/1949 21:00     NaN  1949\n",
       "2  10/10/1955 17:00      gb  1955\n",
       "3  10/10/1956 21:00      us  1956\n",
       "4  10/10/1960 20:00      us  1960"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adjusting times from datetime\n",
    "def adjust_time(time_str):\n",
    "    if \"24:00\" in time_str:\n",
    "        time_str = time_str.replace(\"24:00\", \"00:00\")\n",
    "    return time_str\n",
    "\n",
    "## adjust time\n",
    "scrubbed_location_df['datetime'] = \\\n",
    "                    scrubbed_location_df['datetime'].apply(adjust_time)\n",
    "\n",
    "## finish time formatting by subtracting year \n",
    "scrubbed_location_df['year'] = pd.to_datetime(scrubbed_location_df['datetime'], \n",
    "                                              format='%m/%d/%Y %H:%M').dt.year\n",
    "\n",
    "scrubbed_location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd6559bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrubbed_location_df.to_csv(\"scrubbed_location\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b00947",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c2258",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc86ad",
   "metadata": {},
   "source": [
    "<a name=\"ufotwo\"></a>\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: UFO Sightings, Part Two &#9664;</div>**\n",
    "Since the previous data only showed five countries, we set out to find a more inclusive dataset since the rest of our data (except for the drug use data, which we analyze seperately later) is international. We were unable to find such a dataset online, or even a table with more than just the data found in UFO Sightings Part One. So, instead, we noticed that the NUFORC had webpages for individual sightings. \n",
    "\n",
    "We read in country code map that allows us to produce a country code for each country name, later allowing us to merge on country code any data with only the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a25f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Country', '2', 'Code', 'num'], dtype='object')\n",
      "{'Afghanistan': 'AFG', 'Albania': 'ALB', 'Algeria': 'DZA', 'American Samoa': 'ASM', 'Andorra': 'AND', 'Angola': 'AGO', 'Anguilla': 'AIA', 'Antarctica': 'ATA', 'Antigua and Barbuda': 'ATG', 'Argentina': 'ARG', 'Armenia': 'ARM', 'Aruba': 'ABW', 'Australia': 'AUS', 'Austria': 'AUT', 'Azerbaijan': 'AZE', 'Bahamas (the)': 'BHS', 'Bahrain': 'BHR', 'Bangladesh': 'BGD', 'Barbados': 'BRB', 'Belarus': 'BLR', 'Belgium': 'BEL', 'Belize': 'BLZ', 'Benin': 'BEN', 'Bermuda': 'BMU', 'Bhutan': 'BTN', 'Bolivia (Plurinational State of)': 'BOL', 'Bonaire, Sint Eustatius and Saba': 'BES', 'Bosnia and Herzegovina': 'BIH', 'Botswana': 'BWA', 'Bouvet Island': 'BVT', 'Brazil': 'BRA', 'British Indian Ocean Territory (the)': 'IOT', 'Brunei Darussalam': 'BRN', 'Bulgaria': 'BGR', 'Burkina Faso': 'BFA', 'Burundi': 'BDI', 'Cabo Verde': 'CPV', 'Cambodia': 'KHM', 'Cameroon': 'CMR', 'Canada': 'CAN', 'Cayman Islands (the)': 'CYM', 'Central African Republic (the)': 'CAF', 'Chad': 'TCD', 'Chile': 'CHL', 'China': 'CHN', 'Christmas Island': 'CXR', 'Cocos (Keeling) Islands (the)': 'CCK', 'Colombia': 'COL', 'Comoros (the)': 'COM', 'Congo (the Democratic Republic of the)': 'COD', 'Congo (the)': 'COG', 'Cook Islands (the)': 'COK', 'Costa Rica': 'CRI', 'Croatia': 'HRV', 'Cuba': 'CUB', 'Curaçao': 'CUW', 'Cyprus': 'CYP', 'Czechia': 'CZE', \"Côte d'Ivoire\": 'CIV', 'Denmark': 'DNK', 'Djibouti': 'DJI', 'Dominica': 'DMA', 'Dominican Republic (the)': 'DOM', 'Ecuador': 'ECU', 'Egypt': 'EGY', 'El Salvador': 'SLV', 'Equatorial Guinea': 'GNQ', 'Eritrea': 'ERI', 'Estonia': 'EST', 'Eswatini': 'SWZ', 'Ethiopia': 'ETH', 'Falkland Islands (the) [Malvinas]': 'FLK', 'Faroe Islands (the)': 'FRO', 'Fiji': 'FJI', 'Finland': 'FIN', 'France': 'FRA', 'French Guiana': 'GUF', 'French Polynesia': 'PYF', 'French Southern Territories (the)': 'ATF', 'Gabon': 'GAB', 'Gambia (the)': 'GMB', 'Georgia': 'GEO', 'Germany': 'DEU', 'Ghana': 'GHA', 'Gibraltar': 'GIB', 'Greece': 'GRC', 'Greenland': 'GRL', 'Grenada': 'GRD', 'Guadeloupe': 'GLP', 'Guam': 'GUM', 'Guatemala': 'GTM', 'Guernsey': 'GGY', 'Guinea': 'GIN', 'Guinea-Bissau': 'GNB', 'Guyana': 'GUY', 'Haiti': 'HTI', 'Heard Island and McDonald Islands': 'HMD', 'Holy See (the)': 'VAT', 'Honduras': 'HND', 'Hong Kong': 'HKG', 'Hungary': 'HUN', 'Iceland': 'ISL', 'India': 'IND', 'Indonesia': 'IDN', 'Iran (Islamic Republic of)': 'IRN', 'Iraq': 'IRQ', 'Ireland': 'IRL', 'Isle of Man': 'IMN', 'Israel': 'ISR', 'Italy': 'ITA', 'Jamaica': 'JAM', 'Japan': 'JPN', 'Jersey': 'JEY', 'Jordan': 'JOR', 'Kazakhstan': 'KAZ', 'Kenya': 'KEN', 'Kiribati': 'KIR', \"Korea (the Democratic People's Republic of)\": 'PRK', 'Korea (the Republic of)': 'KOR', 'Kuwait': 'KWT', 'Kyrgyzstan': 'KGZ', \"Lao People's Democratic Republic (the)\": 'LAO', 'Latvia': 'LVA', 'Lebanon': 'LBN', 'Lesotho': 'LSO', 'Liberia': 'LBR', 'Libya': 'LBY', 'Liechtenstein': 'LIE', 'Lithuania': 'LTU', 'Luxembourg': 'LUX', 'Macao': 'MAC', 'Madagascar': 'MDG', 'Malawi': 'MWI', 'Malaysia': 'MYS', 'Maldives': 'MDV', 'Mali': 'MLI', 'Malta': 'MLT', 'Marshall Islands (the)': 'MHL', 'Martinique': 'MTQ', 'Mauritania': 'MRT', 'Mauritius': 'MUS', 'Mayotte': 'MYT', 'Mexico': 'MEX', 'Micronesia (Federated States of)': 'FSM', 'Moldova (the Republic of)': 'MDA', 'Monaco': 'MCO', 'Mongolia': 'MNG', 'Montenegro': 'MNE', 'Montserrat': 'MSR', 'Morocco': 'MAR', 'Mozambique': 'MOZ', 'Myanmar': 'MMR', 'Namibia': 'NAM', 'Nauru': 'NRU', 'Nepal': 'NPL', 'Netherlands (the)': 'NLD', 'Netherlands': 'NLD', 'New Caledonia': 'NCL', 'New Zealand': 'NZL', 'Nicaragua': 'NIC', 'Niger (the)': 'NER', 'Nigeria': 'NGA', 'Niue': 'NIU', 'Norfolk Island': 'NFK', 'Northern Mariana Islands (the)': 'MNP', 'Norway': 'NOR', 'Oman': 'OMN', 'Pakistan': 'PAK', 'Palau': 'PLW', 'Palestine, State of': 'PSE', 'Panama': 'PAN', 'Papua New Guinea': 'PNG', 'Paraguay': 'PRY', 'Peru': 'PER', 'Philippines (the)': 'PHL', 'Pitcairn': 'PCN', 'Poland': 'POL', 'Portugal': 'PRT', 'Puerto Rico': 'PRI', 'Qatar': 'QAT', 'Republic of North Macedonia': 'MKD', 'Romania': 'ROU', 'Russian Federation (the)': 'RUS', 'Rwanda': 'RWA', 'Réunion': 'REU', 'Saint Barthélemy': 'BLM', 'Saint Helena, Ascension and Tristan da Cunha': 'SHN', 'Saint Kitts and Nevis': 'KNA', 'Saint Lucia': 'LCA', 'Saint Martin (French part)': 'MAF', 'Saint Pierre and Miquelon': 'SPM', 'Saint Vincent and the Grenadines': 'VCT', 'Samoa': 'WSM', 'San Marino': 'SMR', 'Sao Tome and Principe': 'STP', 'Saudi Arabia': 'SAU', 'Senegal': 'SEN', 'Serbia': 'SRB', 'Seychelles': 'SYC', 'Sierra Leone': 'SLE', 'Singapore': 'SGP', 'Sint Maarten (Dutch part)': 'SXM', 'Slovakia': 'SVK', 'Slovenia': 'SVN', 'Solomon Islands': 'SLB', 'Somalia': 'SOM', 'South Africa': 'ZAF', 'South Georgia and the South Sandwich Islands': 'SGS', 'South Sudan': 'SSD', 'Spain': 'ESP', 'Sri Lanka': 'LKA', 'Sudan (the)': 'SDN', 'Suriname': 'SUR', 'Svalbard and Jan Mayen': 'SJM', 'Sweden': 'SWE', 'Switzerland': 'CHE', 'Syrian Arab Republic': 'SYR', 'Taiwan (Province of China)': 'TWN', 'Tajikistan': 'TJK', 'Tanzania, United Republic of': 'TZA', 'Thailand': 'THA', 'Timor-Leste': 'TLS', 'Togo': 'TGO', 'Tokelau': 'TKL', 'Tonga': 'TON', 'Trinidad and Tobago': 'TTO', 'Tunisia': 'TUN', 'Turkey': 'TUR', 'Turkmenistan': 'TKM', 'Turks and Caicos Islands (the)': 'TCA', 'Tuvalu': 'TUV', 'Uganda': 'UGA', 'Ukraine': 'UKR', 'United Arab Emirates (the)': 'ARE', 'United Kingdom of Great Britain and Northern Ireland (the)': 'GBR', 'United States Minor Outlying Islands (the)': 'UMI', 'United States of America (the)': 'USA', 'United States': 'USA', 'Uruguay': 'URY', 'Uzbekistan': 'UZB', 'Vanuatu': 'VUT', 'Venezuela (Bolivarian Republic of)': 'VEN', 'Viet Nam': 'VNM', 'Virgin Islands (British)': 'VGB', 'Virgin Islands (U.S.)': 'VIR', 'Wallis and Futuna': 'WLF', 'Western Sahara': 'ESH', 'Yemen': 'YEM', 'Zambia': 'ZMB', 'Zimbabwe': 'ZWE', 'Åland Islands': 'ALA'}\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('country_map.txt', delimiter='\\t')\n",
    "print(data.columns)\n",
    "country_map = dict(zip(data['Country'], data['Code']))\n",
    "\n",
    "print(country_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e1dd0",
   "metadata": {},
   "source": [
    "We then wrote a loop that would go through each page, changing the id number at the end of the URL, and scrape the data using regex and beautiful soup so that we could get more diverse data on UFO sightings. We scraped just the location and the occurred time where location was valid (not just \"local\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c36f939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurred</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-02-22 15:45:00 Local</td>\n",
       "      <td>Netherlands, , Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-30 23:15:00 Local</td>\n",
       "      <td>Amelia (suburb of Cincinnati), OH, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-05 20:17:00 Local</td>\n",
       "      <td>Harrisburg, PA, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-03 20:30:00 Local</td>\n",
       "      <td>Ballston, NY, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-10 05:35:00 Local</td>\n",
       "      <td>Tampa, FL, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Occurred                                 Location\n",
       "0   2005-02-22 15:45:00 Local               Netherlands, , Netherlands\n",
       "0   2020-05-30 23:15:00 Local   Amelia (suburb of Cincinnati), OH, USA\n",
       "0   2020-03-05 20:17:00 Local                      Harrisburg, PA, USA\n",
       "0   2020-10-03 20:30:00 Local                        Ballston, NY, USA\n",
       "0   2017-05-10 05:35:00 Local                           Tampa, FL, USA"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2950)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Occurred\", \"Location\"])\n",
    "base_url = \"https://nuforc.org/sighting/?id=\"\n",
    "\n",
    "session = requests.Session()  # Create a persistent session outside the loop\n",
    "\n",
    "numbers = list(range(1, 1000001))\n",
    "np.random.shuffle(numbers)\n",
    "\n",
    "for number in range(89,1090):\n",
    "    empty_series = pd.Series({\n",
    "        \"Occurred\": \"\",\n",
    "        \"Location\": \"\"\n",
    "    })\n",
    "\n",
    "    url = base_url + str(numbers[number])\n",
    "    response = session.get(url)\n",
    "   \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        occurredtext = str(soup.b.next_sibling.string)\n",
    "        if occurredtext == 'Local':\n",
    "            continue\n",
    "        locationtext = str(soup.b.next_sibling.next_sibling.next_sibling.next_sibling.string)\n",
    "\n",
    "        empty_series[\"Occurred\"] = empty_series[\"Occurred\"] + occurredtext\n",
    "        empty_series[\"Location\"] = empty_series[\"Location\"] + locationtext\n",
    "       \n",
    "        df = pd.concat([df, empty_series.to_frame().T])\n",
    "\n",
    "alien_df = df[df['Occurred'] != '  Local']\n",
    "alien_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c4da2",
   "metadata": {},
   "source": [
    "We slice the data to get only the year and the country from our ufo sightings dataframe, as these are the values we plan on merging on later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "126356ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alien_df_copy = alien_df.copy()\n",
    "\n",
    "def loc_fix(string, key):\n",
    "    last_index = string.rfind(key)\n",
    "    if last_index != -1:\n",
    "        rest_of_string = string[last_index + len(key):]\n",
    "        return rest_of_string.strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for number in range(0,(alien_df_copy.shape[0])):\n",
    "    occur = alien_df_copy.iloc[number, 0]\n",
    "    occur = occur[:occur.find(\"-\")].strip()\n",
    "    alien_df_copy.iloc[number, 0] = occur\n",
    "    \n",
    "    location = alien_df_copy.iloc[number, 1]\n",
    "    location = loc_fix(location, \",\")\n",
    "    alien_df_copy.iloc[number, 1] = location\n",
    "    \n",
    "alien_df = alien_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e0d47",
   "metadata": {},
   "source": [
    "We now update all locations in our alien_df to be in country codes instead of actual countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c85ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "alien_df_copy = alien_df.copy()\n",
    "\n",
    "alien_df_copy['Location'] = alien_df_copy['Location'].map(country_map).fillna(alien_df_copy['Location'])\n",
    "alien_df = alien_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3649c",
   "metadata": {},
   "source": [
    "In order to get the sums of the numbers of sightings per year for each country, we first pivot the table to sum up each year as a categorical variable. Then, we melt that new table to create a tall dataframe with the sums of sightings for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ca41eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country Code  Year  Sightings\n",
      "0              ARG  1959          0\n",
      "1              AUS  1959          0\n",
      "2              BRA  1959          0\n",
      "3              CAN  1959          0\n",
      "4  Channel Islands  1959          0\n",
      "5              DNK  1959          0\n",
      "6              HRV  1959          0\n",
      "7              IND  1959          0\n",
      "8              NLD  1959          0\n",
      "9              USA  1959          1\n",
      "[ 0  1  2  3  4  5  9  7  6 11 12]\n"
     ]
    }
   ],
   "source": [
    "pivot_df = alien_df.pivot_table(index=\"Location\", columns=\"Occurred\", aggfunc='size', fill_value=0)\n",
    "pivot_df.columns = pivot_df.columns.astype(str)\n",
    "\n",
    "melted_df = pivot_df.reset_index().melt(id_vars='Location', var_name='Year', value_name='Value')\n",
    "melted_df = melted_df.rename(columns={'Location': 'Country Code', 'Value': 'Sightings'})\n",
    "alien_df = melted_df\n",
    "print(melted_df.head(10))\n",
    "print(melted_df.iloc[:,2].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08855b71",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a36110a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alien_df.to_csv(\"alien_info\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190c7ce",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca245d04",
   "metadata": {},
   "source": [
    "<a name=\"combining\"></a>\n",
    "\n",
    "## **<div align=\"center\">&#9658; Data Cleaning: Combining the Dataframes &#9664;</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb8c94",
   "metadata": {},
   "source": [
    "We make a list of our dataframes and print out the first rows to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab91cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Entity Code  Year  avg_years_of_schooling\n",
      "0  Afghanistan  AFG  1870                    0.01\n",
      "----------------------------------\n",
      "  Country Name Country Code  1960  1961  1962  1963  1964  1965  1966  1967  \\\n",
      "0        Aruba          ABW   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   ...  2013   2014       2015       2016   2017  2018  2019  2020  2021  2022  \n",
      "0  ...  78.9  83.78  88.661227  93.542454  97.17   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[1 rows x 65 columns]\n",
      "----------------------------------\n",
      "  Country     Regime_Type  Year  Democracy_Index\n",
      "0  Canada  Full democracy  2022             8.88\n",
      "----------------------------------\n",
      "   rounded year code              topReligion\n",
      "0          1945  USA  christianity_protestant\n",
      "----------------------------------\n",
      "   Year  Countries  Wealth_share_percent\n",
      "0  2000  Australia                   NaN\n",
      "----------------------------------\n",
      "  Country Code  Year  Sightings\n",
      "0          ARG  1959          0\n"
     ]
    }
   ],
   "source": [
    "dfs = [education_df, internet_df, political_df, religion_df, wealth_df, alien_df]\n",
    "\n",
    "print(education_df.head(1))\n",
    "print(\"----------------------------------\")\n",
    "print(internet_df.head(1))\n",
    "print(\"----------------------------------\")\n",
    "print(political_df.head(1))\n",
    "print(\"----------------------------------\")\n",
    "print(religion_df.head(1))\n",
    "print(\"----------------------------------\")\n",
    "print(wealth_df.head(1))\n",
    "print(\"----------------------------------\")\n",
    "print(alien_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ece09",
   "metadata": {},
   "source": [
    "We type cast all of the columns in order to make them the same type so that we can merge everything together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f88bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.columns = [np.str_(col) for col in df.columns]\n",
    "for df in dfs:\n",
    "    if 'Year' in df.columns:\n",
    "        df['Year'] = df['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebfef7",
   "metadata": {},
   "source": [
    "We merge our education data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc779cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country Code  Year  Sightings Entity  avg_years_of_schooling\n",
      "0              ARG  1959          0    NaN                     NaN\n",
      "1              AUS  1959          0    NaN                     NaN\n",
      "2              BRA  1959          0    NaN                     NaN\n",
      "3              CAN  1959          0    NaN                     NaN\n",
      "4  Channel Islands  1959          0    NaN                     NaN\n"
     ]
    }
   ],
   "source": [
    "#adding educaiton\n",
    "merged_df = pd.merge(alien_df, \n",
    "                     education_df, \n",
    "                     left_on=['Country Code', 'Year'], \n",
    "                     right_on=['Code', 'Year'], \n",
    "                     how='left')\n",
    "merged_df.drop(columns='Code', inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d653a",
   "metadata": {},
   "source": [
    "We merge our internet access data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5896fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n8/5lk2zknn785fwp1_wzpmgts80000gn/T/ipykernel_5185/3699339001.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m merged_df = pd.merge(merged_df, \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0minternet_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country Code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      how='left')\n",
      "\u001b[0;32m~/anaconda3/envs/Info2950/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 148\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Info2950/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m         (\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Info2950/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Info2950/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(merged_df, \n",
    "                     internet_df, \n",
    "                     on=['Country Code', 'Year'], \n",
    "                     how='left')\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560a6ff",
   "metadata": {},
   "source": [
    "We merge our religion data. We make these factors dummy variables since they are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, \n",
    "                     religion_df, \n",
    "                     left_on=['Country Code', 'Year'], \n",
    "                     right_on=['code', 'Year'],\n",
    "                     how='left')\n",
    "\n",
    "religion_dummies = pd.get_dummies(merged_df['topReligion'])\n",
    "religion_dummies = religion_dummies.astype(int)\n",
    "merged_df = pd.concat([merged_df, religion_dummies], axis=1)\n",
    "merged_df.drop('topReligion', axis=1, inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e86162",
   "metadata": {},
   "source": [
    "We turn the country names of the political and wealth data into country codes to merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d195c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_df['Country'] = political_df['Country'].map(country_map).fillna(political_df['Country'])\n",
    "wealth_df['Countries'] = wealth_df['Countries'].map(country_map).fillna(wealth_df['Countries'])\n",
    "\n",
    "print(wealth_df.head(1))\n",
    "print(political_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa129d",
   "metadata": {},
   "source": [
    "We merge our politcal data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, \n",
    "                     political_df, \n",
    "                     left_on=['Country Code', 'Year'],\n",
    "                     right_on=['Country', 'Year'], how='left')\n",
    "merged_df.drop(columns='Country', inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac90a34",
   "metadata": {},
   "source": [
    "We merge our wealth data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84340c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, \n",
    "                     wealth_df, \n",
    "                     left_on=['Country Code', 'Year'], \n",
    "                     right_on=['Countries', 'Year'], \n",
    "                     how='left')\n",
    "merged_df.drop(columns='Countries', inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b2113",
   "metadata": {},
   "source": [
    "Due to the splicing of other dataframes, we make everything_df our final dataframe as a copy of merge to create its own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_df = merged_df.copy()\n",
    "everything_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a5e22",
   "metadata": {},
   "source": [
    "We check the types of the columns after modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcb4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(everything_df.iloc[:,0].unique())\n",
    "everything_df.columns = [np.str_(col) for col in everything_df.columns]\n",
    "\n",
    "for col in everything_df.columns:\n",
    "    print(type(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627fab7a",
   "metadata": {},
   "source": [
    "We replace NaN values with the mean of the associated column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a601804",
   "metadata": {},
   "source": [
    "Imputer = SimpleImputer(strategy='mean')\n",
    "columns_to_impute = ['Year', 'Average Years of Schooling', 'internet access',\n",
    "                     'christianity_protestant', 'christianity_romancatholic',\n",
    "                     'Democracy_Index', 'Wealth_share_percent']\n",
    "everything_df[columns_to_impute] = imputer.fit_transform(everything_df[columns_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9d143",
   "metadata": {},
   "source": [
    "We display the final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(everything_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ba277",
   "metadata": {},
   "source": [
    "We save the dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cec962",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_df.to_csv(\"final_df\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41532914",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59c515",
   "metadata": {},
   "source": [
    "## Other Sources\n",
    "\n",
    "1. Used for formatting of Markdown outside of what was covered in class: https://www.ibm.com/docs/en/db2-event-store/2.0.0?topic=notebooks-markdown-jupyter-cheatsheet \n",
    "1. Used while creating top_df to solve a SettingWithCopyError: https://github.com/pandas-dev/pandas/issues/39418 \n",
    "1. Used to get country codes and corresponding countruy names: https://www.iban.com/country-codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
